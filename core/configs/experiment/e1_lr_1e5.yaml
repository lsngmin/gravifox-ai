# Experiment E1-A: Learning rate sweep (1e-5)
experiment_name: e1_lr_1e5

run:
  seed: 1337
  output_dir: ${oc.env:TVB_EXPERIMENT_ROOT,${hydra:runtime.cwd}/experiments}/${experiment_name}/${now:%Y%m%d_%H%M%S}

optimizer:
  name: adamw
  lr: 1.0e-5
  weight_decay: 0.05

trainer:
  partial_epochs: 35
  full_epochs: 5
  partial_steps: 10000
  full_steps: -1
  grad_accum_steps: 2
  label_smoothing: 0.1

notes: "AdamW lr sweep - low"
